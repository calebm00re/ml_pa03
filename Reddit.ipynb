{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       ID Tag  Reputation  Answers  Username    Views  Upvotes\n0   52664   a      3942.0      2.0    155623   7855.0     42.0\n1  327662   a     26046.0     12.0     21781  55801.0   1175.0\n2  468453   c      1358.0      4.0     56177   8067.0     60.0\n3   96996   a       264.0      3.0    168793  27064.0      9.0\n4  131465   c      4271.0      4.0    112223  13986.0     83.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Tag</th>\n      <th>Reputation</th>\n      <th>Answers</th>\n      <th>Username</th>\n      <th>Views</th>\n      <th>Upvotes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52664</td>\n      <td>a</td>\n      <td>3942.0</td>\n      <td>2.0</td>\n      <td>155623</td>\n      <td>7855.0</td>\n      <td>42.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>327662</td>\n      <td>a</td>\n      <td>26046.0</td>\n      <td>12.0</td>\n      <td>21781</td>\n      <td>55801.0</td>\n      <td>1175.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>468453</td>\n      <td>c</td>\n      <td>1358.0</td>\n      <td>4.0</td>\n      <td>56177</td>\n      <td>8067.0</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96996</td>\n      <td>a</td>\n      <td>264.0</td>\n      <td>3.0</td>\n      <td>168793</td>\n      <td>27064.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>131465</td>\n      <td>c</td>\n      <td>4271.0</td>\n      <td>4.0</td>\n      <td>112223</td>\n      <td>13986.0</td>\n      <td>83.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit = pd.read_csv(\"datasets/upvotes.csv\")\n",
    "reddit.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(330045, 7)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 330045 entries, 0 to 330044\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   ID          330045 non-null  int64  \n",
      " 1   Tag         330045 non-null  object \n",
      " 2   Reputation  330045 non-null  float64\n",
      " 3   Answers     330045 non-null  float64\n",
      " 4   Username    330045 non-null  int64  \n",
      " 5   Views       330045 non-null  float64\n",
      " 6   Upvotes     330045 non-null  float64\n",
      "dtypes: float64(4), int64(2), object(1)\n",
      "memory usage: 17.6+ MB\n"
     ]
    }
   ],
   "source": [
    "reddit.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "reddit = reddit.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 330045 entries, 0 to 330044\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   ID          330045 non-null  int64  \n",
      " 1   Tag         330045 non-null  object \n",
      " 2   Reputation  330045 non-null  float64\n",
      " 3   Answers     330045 non-null  float64\n",
      " 4   Username    330045 non-null  int64  \n",
      " 5   Views       330045 non-null  float64\n",
      " 6   Upvotes     330045 non-null  float64\n",
      "dtypes: float64(4), int64(2), object(1)\n",
      "memory usage: 20.1+ MB\n"
     ]
    }
   ],
   "source": [
    "reddit.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "c    72458\nj    72232\np    43407\ni    32400\na    31695\ns    23323\nh    20564\no    14546\nr    12442\nx     6978\nName: Tag, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit['Tag'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Going to one hot encode the above values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<330045x10 sparse matrix of type '<class 'numpy.float64'>'\n\twith 330045 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohEncoder = OneHotEncoder()\n",
    "tag_cat = reddit[[\"Tag\"]]\n",
    "tags = ohEncoder.fit_transform(tag_cat)\n",
    "tags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[array(['a', 'c', 'h', 'i', 'j', 'o', 'p', 'r', 's', 'x'], dtype=object)]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohEncoder.categories_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### transforming to add new column that shows the views ratioed by the reputation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "       ID Tag  Reputation  Answers  Username    Views  Upvotes  ViewsPerPop\n0   52664   a      3942.0      2.0    155623   7855.0     42.0     1.992643\n1  327662   a     26046.0     12.0     21781  55801.0   1175.0     2.142402\n2  468453   c      1358.0      4.0     56177   8067.0     60.0     5.940353\n3   96996   a       264.0      3.0    168793  27064.0      9.0   102.515152\n4  131465   c      4271.0      4.0    112223  13986.0     83.0     3.274643",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Tag</th>\n      <th>Reputation</th>\n      <th>Answers</th>\n      <th>Username</th>\n      <th>Views</th>\n      <th>Upvotes</th>\n      <th>ViewsPerPop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52664</td>\n      <td>a</td>\n      <td>3942.0</td>\n      <td>2.0</td>\n      <td>155623</td>\n      <td>7855.0</td>\n      <td>42.0</td>\n      <td>1.992643</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>327662</td>\n      <td>a</td>\n      <td>26046.0</td>\n      <td>12.0</td>\n      <td>21781</td>\n      <td>55801.0</td>\n      <td>1175.0</td>\n      <td>2.142402</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>468453</td>\n      <td>c</td>\n      <td>1358.0</td>\n      <td>4.0</td>\n      <td>56177</td>\n      <td>8067.0</td>\n      <td>60.0</td>\n      <td>5.940353</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96996</td>\n      <td>a</td>\n      <td>264.0</td>\n      <td>3.0</td>\n      <td>168793</td>\n      <td>27064.0</td>\n      <td>9.0</td>\n      <td>102.515152</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>131465</td>\n      <td>c</td>\n      <td>4271.0</td>\n      <td>4.0</td>\n      <td>112223</td>\n      <td>13986.0</td>\n      <td>83.0</td>\n      <td>3.274643</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "# Going to use the apply function similar to the transform function\n",
    "\n",
    "#make sure no reputation values are zero so division by zero will not happen\n",
    "reddit = reddit[reddit.Reputation != 0]\n",
    "reddit['ViewsPerPop'] = reddit.apply(lambda row : row.Views / row.Reputation, axis = 1)\n",
    "reddit.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### using ensemble methods to get a predictor for upvotes\n",
    "\n",
    "[source](https://www.geeksforgeeks.org/ensemble-methods-in-python/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 7)\n",
      "ensamble mean squared error: 636669.9234495836\n",
      "thats a lot of error, this predicted data is awful\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "reddit = pd.read_csv(\"datasets/upvotes.csv\")\n",
    "\n",
    "reddit = reddit[reddit.Upvotes != 0]\n",
    "\n",
    "reddit = reddit.head(500)\n",
    "print(reddit.shape)\n",
    "\n",
    "reddit = reddit[reddit.Reputation != 0]\n",
    "reddit['ViewsPerPop'] = reddit.apply(lambda row : row.Views / row.Reputation, axis = 1)\n",
    "\n",
    "reddit = reddit.drop(['Username', 'ID', 'Answers'], axis=1)\n",
    "\n",
    "reddit = pd.get_dummies(reddit)\n",
    "upvotes = np.array(reddit['Upvotes'])\n",
    "\n",
    "reddit = reddit.drop(['Upvotes'], axis=1)\n",
    "\n",
    "reddit_list = list(reddit.columns)\n",
    "\n",
    "reddit = np.array(reddit)\n",
    "\n",
    "train_reddit, test_reddit, train_upvotes, test_upvotes = train_test_split(reddit, upvotes, test_size = 0.25, random_state = 42)\n",
    "\n",
    "rf1 = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf1.fit(train_reddit, train_upvotes)\n",
    "rf1_pred = rf1.predict(test_reddit)\n",
    "\n",
    "rf2 = LinearRegression()\n",
    "rf2.fit(train_reddit, train_upvotes)\n",
    "rf2_pred = rf2.predict(test_reddit)\n",
    "\n",
    "rf3 = KNeighborsClassifier(n_neighbors=9)\n",
    "rf3.fit(train_reddit, train_upvotes)\n",
    "rf3_pred = rf3.predict(test_reddit)\n",
    "\n",
    "#get the average of the three models for the ensemble model\n",
    "eavg = (rf1_pred + rf2_pred + rf3_pred)/3\n",
    "\n",
    "#print error\n",
    "print(\"ensamble mean squared error:\", sklearn.metrics.mean_squared_error(test_upvotes, eavg))\n",
    "print('thats a lot of error, this predicted data is awful')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### simple start to prediction pipeline rand. forest\n",
    "[followed this example](https://towardsdatascience.com/random-forest-in-python-24d0893d51c0)\n",
    "\n",
    "edit: not too happy with the accuracy so lets attempt a pipeline for linear regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7)\n",
      "Mean Absolute Error: 152.81 degrees.\n",
      "Accuracy: -33.09 %.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reddit = pd.read_csv(\"datasets/upvotes.csv\")\n",
    "\n",
    "#realizing shape makes this take forever\n",
    "# print(reddit.shape)\n",
    "reddit = reddit[reddit.Upvotes != 0]\n",
    "# reddit = reddit[reddit.Answers != 0]\n",
    "# reddit = reddit[reddit.Reputation != 0]\n",
    "\n",
    "reddit = reddit.head(10000)\n",
    "print(reddit.shape)\n",
    "\n",
    "reddit = reddit[reddit.Reputation != 0]\n",
    "reddit['ViewsPerPop'] = reddit.apply(lambda row : row.Views / row.Reputation, axis = 1)\n",
    "\n",
    "reddit = reddit.drop(['Username', 'ID', 'Answers'], axis=1)\n",
    "\n",
    "reddit = pd.get_dummies(reddit)\n",
    "upvotes = np.array(reddit['Upvotes'])\n",
    "\n",
    "reddit = reddit.drop(['Upvotes'], axis=1)\n",
    "\n",
    "reddit_list = list(reddit.columns)\n",
    "\n",
    "reddit = np.array(reddit)\n",
    "\n",
    "train_reddit, test_reddit, train_upvotes, test_upvotes = train_test_split(reddit, upvotes, test_size = 0.25, random_state = 42)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(train_reddit, train_upvotes)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_reddit)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_upvotes)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_upvotes)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### simple start to prediction pipeline linear\n",
    "this one is not much better. this data may just suck"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7)\n",
      "coefficient of determination: 0.37474032124673706\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reddit = pd.read_csv(\"datasets/upvotes.csv\")\n",
    "\n",
    "#realizing shape makes this take forever\n",
    "# print(reddit.shape)\n",
    "reddit = reddit[reddit.Upvotes != 0]\n",
    "# reddit = reddit[reddit.Answers != 0]\n",
    "# reddit = reddit[reddit.Reputation != 0]\n",
    "\n",
    "reddit = reddit.head(10000)\n",
    "print(reddit.shape)\n",
    "\n",
    "reddit = reddit[reddit.Reputation != 0]\n",
    "reddit['ViewsPerPop'] = reddit.apply(lambda row : row.Views / row.Reputation, axis = 1)\n",
    "\n",
    "reddit = reddit.drop(['Username', 'ID', 'Answers'], axis=1)\n",
    "\n",
    "reddit = pd.get_dummies(reddit)\n",
    "upvotes = np.array(reddit['Upvotes'])\n",
    "\n",
    "reddit = reddit.drop(['Upvotes'], axis=1)\n",
    "\n",
    "reddit_list = list(reddit.columns)\n",
    "\n",
    "reddit = np.array(reddit)\n",
    "\n",
    "train_reddit, test_reddit, train_upvotes, test_upvotes = train_test_split(reddit, upvotes, test_size = 0.25, random_state = 42)\n",
    "\n",
    "rf = LinearRegression()\n",
    "rf.fit(train_reddit, train_upvotes)\n",
    "\n",
    "#coefficient of determination\n",
    "print('coefficient of determination:', rf.score(train_reddit, train_upvotes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### going to try to pipeline with SGDClassifier\n",
    "beginning to think these just have awful accuracy for predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 7)\n",
      "Accuracy:  0.013333333333333334\n"
     ]
    }
   ],
   "source": [
    "#pipeline for SGDClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "reddit = pd.read_csv(\"datasets/upvotes.csv\")\n",
    "\n",
    "#realizing shape makes this take forever\n",
    "# print(reddit.shape)\n",
    "reddit = reddit[reddit.Upvotes != 0]\n",
    "# reddit = reddit[reddit.Answers != 0]\n",
    "# reddit = reddit[reddit.Reputation != 0]\n",
    "\n",
    "reddit = reddit.head(300)\n",
    "print(reddit.shape)\n",
    "\n",
    "reddit = reddit[reddit.Reputation != 0]\n",
    "reddit['ViewsPerPop'] = reddit.apply(lambda row : row.Views / row.Reputation, axis = 1)\n",
    "\n",
    "reddit = reddit.drop(['Username', 'ID', 'Answers'], axis=1)\n",
    "\n",
    "reddit = pd.get_dummies(reddit)\n",
    "upvotes = np.array(reddit['Upvotes'])\n",
    "\n",
    "reddit = reddit.drop(['Upvotes'], axis=1)\n",
    "\n",
    "reddit_list = list(reddit.columns)\n",
    "\n",
    "reddit = np.array(reddit)\n",
    "\n",
    "train_reddit, test_reddit, train_upvotes, test_upvotes = train_test_split(reddit, upvotes, test_size = 0.25, random_state = 42)\n",
    "\n",
    "rf = SGDClassifier(random_state=42, max_iter=1000)\n",
    "rf.fit(train_reddit, train_upvotes)\n",
    "\n",
    "y_pred = rf.predict(test_reddit)\n",
    "print(\"Accuracy: \",accuracy_score(test_upvotes, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### going to try to pipeline with KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 7)\n",
      "Accuracy:  0.05333333333333334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "reddit = pd.read_csv(\"datasets/upvotes.csv\")\n",
    "\n",
    "#realizing shape makes this take forever\n",
    "# print(reddit.shape)\n",
    "reddit = reddit[reddit.Upvotes != 0]\n",
    "# reddit = reddit[reddit.Answers != 0]\n",
    "# reddit = reddit[reddit.Reputation != 0]\n",
    "\n",
    "reddit = reddit.head(300)\n",
    "print(reddit.shape)\n",
    "\n",
    "reddit = reddit[reddit.Reputation != 0]\n",
    "reddit['ViewsPerPop'] = reddit.apply(lambda row : row.Views / row.Reputation, axis = 1)\n",
    "\n",
    "reddit = reddit.drop(['Username', 'ID', 'Answers'], axis=1)\n",
    "\n",
    "reddit = pd.get_dummies(reddit)\n",
    "upvotes = np.array(reddit['Upvotes'])\n",
    "\n",
    "reddit = reddit.drop(['Upvotes'], axis=1)\n",
    "\n",
    "reddit_list = list(reddit.columns)\n",
    "\n",
    "reddit = np.array(reddit)\n",
    "\n",
    "train_reddit, test_reddit, train_upvotes, test_upvotes = train_test_split(reddit, upvotes, test_size = 0.25, random_state = 42)\n",
    "\n",
    "rf = KNeighborsClassifier(n_neighbors=9)\n",
    "rf.fit(train_reddit, train_upvotes)\n",
    "\n",
    "guess_upvotes = rf.predict(test_reddit)\n",
    "print(\"Accuracy: \",accuracy_score(test_upvotes, guess_upvotes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%#pipeline for SGDClassifier\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 0, ..., 0, 0, 2],\n       [0, 0, 0, ..., 0, 0, 1],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(test_upvotes, y_pred)\n",
    "conf_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### OvR Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 7)\n",
      "Accuracy:  0.03225806451612903\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "reddit = pd.read_csv(\"datasets/upvotes.csv\")\n",
    "\n",
    "reddit = reddit[reddit.Upvotes != 0]\n",
    "\n",
    "reddit = reddit.head(500)\n",
    "print(reddit.shape)\n",
    "\n",
    "reddit = reddit[reddit.Reputation != 0]\n",
    "reddit['ViewsPerPop'] = reddit.apply(lambda row : row.Views / row.Reputation, axis = 1)\n",
    "\n",
    "reddit = reddit.drop(['Username', 'ID', 'Answers'], axis=1)\n",
    "\n",
    "reddit = pd.get_dummies(reddit)\n",
    "upvotes = np.array(reddit['Upvotes'])\n",
    "\n",
    "reddit_ups = reddit['Upvotes']\n",
    "reddit = reddit.drop(['Upvotes'], axis=1)\n",
    "\n",
    "reddit_list = list(reddit.columns)\n",
    "\n",
    "reddit = np.array(reddit)\n",
    "\n",
    "train_reddit, test_reddit, train_upvotes, test_upvotes = train_test_split(reddit, upvotes, test_size = 0.25, random_state = 42)\n",
    "\n",
    "ovr = OneVsRestClassifier(SGDClassifier())\n",
    "ovr.fit(train_reddit, train_upvotes)\n",
    "\n",
    "guess_upvotes = ovr.predict(test_reddit)\n",
    "print(\"Accuracy: \",accuracy_score(test_upvotes, guess_upvotes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 56.,  10.,   8.,  62.,   8.,   1.,   2.,   1., 129., 260.,   8.,\n         8.,  36.,   8.,   5.,  10.,  10.,   9.,   8.,  26.,   7.,  56.,\n        21.,   5.,  56.,  11.,   2.,  26.,   2.,  26.,  48.,  14.,  27.,\n        14.,   2.,  21.,  36., 223.,   2.,   8.,  36.,  14.,   8.,  36.,\n         4.,  98.,   8.,   2.,   1.,   8.,  14.,  26.,  48.,  24.,   7.,\n        98.,   2.,   2.,  36.,  36.,   9.,  10.,  14.,  36.,  65.,   1.,\n        17.,  12.,  56.,  56.,  27.,  56.,  26.,  21.,   2.])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_upvotes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}